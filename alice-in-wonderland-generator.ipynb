{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alice in Wonderland Text Generator\n",
    "See also: https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Load LSTM network and generate text\n",
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS_DIR = 'alice-in-wonderland-data/weights/'\n",
    "TEXT_DIR = 'alice-in-wonderland-data/wonderland.txt'\n",
    "\n",
    "file_list = sorted(os.listdir(WEIGHTS_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = TEXT_DIR\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" hrone\r\n",
      "when they arrived, with a great crowd assembled about them--all sorts of\r\n",
      "little birds and be \"\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "\n",
    "pattern = dataX[start]\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "first = ''.join([int_to_char[value] for value in pattern])\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting phrase: hrone\n",
      "when they arrived, with a great crowd assembled about them--all sorts of\n",
      "little birds and be\n",
      "Model Generation: Epoch  1\n",
      "\n",
      "\n",
      " the hare a care a care a care a care a care a care a care a care a care a care a care the hare a care a care the hare a care a care a care a care a care a care a care a care a care a care the hare a care a care the hare a care a care a care a care a care a care a care a care a care a care the hare a care a care the hare a care a care a care a care a care a care a care a care a care a care the hare a care a care the hare a care a care a care a care a care a care a care a care a care a care the h\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model Generation: Epoch  2\n",
      "\n",
      "\n",
      "are the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool the pool t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model Generation: Epoch  4\n",
      "\n",
      "\n",
      "he project gutenberg-tm electronic works of the project gutenberg-tm electronic works of the project gutenberg-tm electronic works of the project gutenberg-tm electronic works of the project gutenberg-tm electronic works of the project gutenberg-tm electronic works of the project gutenberg-tm electronic works of the project gutenberg-tm electronic works of the project gutenberg-tm electronic works of the project gutenberg-tm electronic works of the project gutenberg-tm electronic works of the pr\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model Generation: Epoch  8\n",
      "\n",
      "\n",
      "oject gutenberg-tm electronic works and the project gutenberg-tm electronic works and the project gutenberg-tm electronic works and the project gutenberg-tm electronic works and the project gutenberg-tm electronic works and the project gutenberg-tm electronic works and the project gutenberg-tm electronic works and the project gutenberg-tm electronic works and the project gutenberg-tm electronic works and the project gutenberg-tm electronic works and the project gutenberg-tm electronic works and \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model Generation: Epoch  16\n",
      "\n",
      "\n",
      "distribution of this agreement, you know, and the project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model Generation: Epoch  32\n",
      "\n",
      "\n",
      " electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a project gutenberg-tm electronic works in a proj\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model Generation: Epoch  40\n",
      "\n",
      "\n",
      "ect\n",
      "gutenberg-tm works in any project gutenberg-tm works in any project gutenberg-tm electronic works in the\n",
      "project gutenberg-tm electronic works in the project gutenberg-tm electronic works in the\n",
      "project gutenberg-tm electronic works in the project gutenberg-tm electronic works in the\n",
      "project gutenberg-tm electronic works in the project gutenberg-tm electronic works in the\n",
      "project gutenberg-tm electronic works in the project gutenberg-tm electronic works in the\n",
      "project gutenberg-tm elec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model Generation: Epoch  43\n",
      "\n",
      "\n",
      "tronic works in the project gutenberg-tm\n",
      "electronic works in the project gutenberg-tm electronic works in the project\n",
      "gutenberg-tm electronic works in the project gutenberg-tm electronic works in the project\n",
      "gutenberg-tm electronic works in the project gutenberg-tm electronic works in the project\n",
      "gutenberg-tm electronic works in the project gutenberg-tm electronic works in the project\n",
      "gutenberg-tm electronic works in the project gutenberg-tm electronic works in the project\n",
      "gutenberg-tm ele\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_list = [1,2,4,8,16,32,40,43]\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(256,20, input_length = 100))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# Text generation \"seed\"\n",
    "pattern = dataX[start]\n",
    "pattern = pattern[:100]\n",
    "\n",
    "# For each epoch we want to display:\n",
    "for (index, epoch) in enumerate(epoch_list):\n",
    "\n",
    "    \n",
    "\t# load the network weights from that epoch\n",
    "\tfilename = \"./alice-in-wonderland-data/weights/%s\" % file_list[index]\n",
    "\tmodel.load_weights(filename)\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "\tif(epoch == 1):\n",
    "\t\tprint('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "\t\tprint(\"Starting phrase: \", end = '') \n",
    "\t\tprint(first)\n",
    "        \n",
    "\tprint(\"Model Generation: Epoch \", epoch)\n",
    "\tprint('\\n')\n",
    "\t# generate characters\n",
    "\tpred_list = []\n",
    "\tfor i in range(500):\n",
    "\t\t#time.sleep(.3)\n",
    "\t\t\n",
    "\t\tx = numpy.reshape(pattern, (1, len(pattern)))\n",
    "\t\t#print(pattern)\n",
    "\t\tprediction = model.predict(x, verbose=0)\n",
    "\n",
    "\t\tindex = numpy.argmax(prediction)\n",
    "\t\tresult = int_to_char[index]\n",
    "\t\tsys.stdout.write(result)\n",
    "\t\tsys.stdout.flush()\n",
    "\t\ttime.sleep(.001)\n",
    "\t\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\t\t#sys.stdout.write(result)\n",
    "\t\tpattern.append(index)\n",
    "\t\tpattern = pattern[1:len(pattern)]\n",
    "\t\n",
    "\tprint(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
